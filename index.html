
<!DOCTYPE html>
<html>

<head>
<title>konstantin genin</title>
<link rel="stylesheet" type="text/css" href="css/main.css">
</head>

<body>


<div id="wrap">
	<div id="header">
	
		<div id="aboveheader"></div>
		
		 <!-- <img id="leftlogo" src="img/portrait.jpg"></img> -->
		
		<div id="headertext">
		<h1>konstantin genin</h1></div>
		
		
		<ul id="nav">
			<li id="currentitem"><a href="index.html">Home</a></li>
			<li><a href="publications.html">Papers</a></li>
      	<li><a href="talk.html">Talks</a></li>
      	<li><a href="teach.html">Teaching</a></li>
      	<!-- <li><a href="contact.html">Contact</a></li> -->
   	</ul>
   </div>

	<div id="content">

<img id="leftlogo" src="img/portrait.jpg"></img> 
		
	  <!-- <h4>Current position</h4>-->
	  I am a fifth-year PhD candidate in the <a href="https://www.cmu.edu/dietrich/philosophy/">Philosophy Department</a> at Carnegie Mellon. My dissertation advisor is <a href="http://www.andrew.cmu.edu/user/kk3n/homepage/kelly.html">Kevin T. Kelly</a>. <!-- <br><br> I have an MSc in <a href="http://www.cmu.edu/dietrich/philosophy/graduate/phd/lcm-phil/index.html">Logic, Computation and Methodology</a> (Carnegie Mellon, 2015) and BAs in Math and Philosophy (Brown, 2009). <br><br> -->  Contact me at <b>first.last at gmail</b>.
	  <h4>Research</h4>
		    <p>Inductive inference, Ockham's razor, reliabilism, formal epistemology, learning theory, belief revision, topology, statistics and machine learning.</p>
		    <p>I study how to make reliable inferences from statistical data.  I believe in <i>feasibility contextualism</i>, the thesis that epistemic justification consists in adopting the most reliable means for arriving at the true answer to the question under investigation, given the kind of data one can hope to receive. On that view, scientific preferences for theoretical virtues like simplicity, unity, or testability can be epistemically justified only by proving that they are necessary for good truth-finding performance. For example, Ockham's razor mandates a preference for simpler theories. Standard justifications do not explain why Ockham's razor is better at finding the truth than competing methods. However, Kelly, Glymour, and Schulte have shown that Ockham's razor is  <i>necessary</i> for keeping inquiry on the straightest path to the truth.  With Kelly, I have extended  that result by refining the underlying notion of simplicity, elaborating the exact sense of ``straightest path,"  and developing a simplicity-driven theory of belief revision better suited to inductive inference than standard AGM theory.
<p>
My thesis work constitutes a major advance for that approach. Previous results were grounded in a non-statistical account of information, on which information states are basic neighborhoods in a topological space.  However, scientific data is statistical, and some critics, including Elliott Sober, doubt that the gap between propositional and statistical information can be bridged. I answer the skeptics by identifying the unique topology on probability measures whose open sets are exactly the statistically verifiable propositions. By means of that bridge result, I obtain a new foundation for Ockham's razor in statistical inference that is securely grounded in the aim of finding the truth, and that neither begs the question with a Bayesian prior bias toward simplicity, nor avoids it by changing the subject from inferring theories to selecting models. Those results establish a revealing new topological framework in which to study real empirical inquiry as practiced in machine learning, statistics and the sciences.
<h4>Education</h4>
I have an MSc in <a href="http://www.cmu.edu/dietrich/philosophy/graduate/phd/lcm-phil/index.html">Logic, Computation and Methodology</a> (Carnegie Mellon, 2015) and BAs in Math and Philosophy (Brown, 2009).
		     	
	</div>

<p id=subs> Last update: 04-2017. </p> 
	

</div>


</body>
</html> 
