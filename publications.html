
<!DOCTYPE html>
<html>

<head>
<title>konstantin genin</title>
<link rel="stylesheet" type="text/css" href="css/main.css">
</head>

<body>


<div id="wrap">
	<div id="header">
	
		<div id="aboveheader"></div>
		
		<div id="headertext">
		<h1>konstantin genin</h1></div>
		
		
		<ul id="nav">
			<li><a href="index.html">HOME</a></li>
			<li id="currentitem"><a href="publications.html">WRITING</a></li>
      	<li><a href="talk.html">TALKS</a></li>
      	<li><a href="teach.html">TEACHING</a></li>
      	<!-- <li><a href="contact.html">Contact</a></li> -->
   	</ul>
   </div>

	<div id="content">



		 <img id="rightlogo" src="img/Ockham2.png" title="Ockham, and his razor."></img>


<ul>
<!-- <h2>Work in Progress</h2> -->
 

  <h2>Published and Forthcoming</h2>
<li><b>Learning, Theory Choice, and Belief Revision. </b> (2018) [<a href="https://www.researchgate.net/publication/316224575_Learning_Theory_Choice_and_Belief_Revision">preprint</a>] [<a href="https://doi.org/10.1007/s11225-018-9809-5">doi</a>]<br>
  Konstantin Genin, Kevin T. Kelly. <br>
  <i> Studia Logica</i>.<br><br>			

This paper presents new logical relations connecting three topics pertaining to inductive inference: (I) synchronic norms of theory choice, like the preferences for simpler and more falsifiable theories, (II) diachronic norms of theory change familiar from belief revision and AGM theory, and (III) the justification of such norms by truth-conduciveness, or learning performance.<br><br>
  </li>

<li><b>The Topology of Statistical Verifiability. </b> (2017) <a href="https://www.researchgate.net/publication/316248593_The_Topology_of_Statistical_Verifiability">[preprint]</a> <a href="http://dx.doi.org/10.4204/EPTCS.251.17">[doi]</a> <br> 
Konstantin Genin, Kevin T. Kelly. <br>
    Accepted for presentation and publication in proceedings of <a href="http://tark17.csc.liv.ac.uk/">TARK 2017</a>, Liverpool. <br><br>
In topological learning theory, open sets are interpreted as hypotheses deductively verifiable by true <i>propositional</i> information that rules out relevant possibilities. However, in statistical data analysis, one routinely receives random samples logically compatible with every statistical hypothesis.  We bridge the gap between propositional and statistical data by solving for the unique topology on probability measures in which the open sets are exactly the <i>statistically verifiable</i> hypotheses. Furthermore, we extend that result to a topological characterization of learnability in the limit from statistical data. <br><br>
</li>


  <li><b>Realism, Rhetoric, and Reliability.</b> (2016) <a href="https://www.researchgate.net/publication/301678339_Realism_rhetoric_and_reliability">[preprint]</a> <a href="http://dx.doi.org/10.1007/s11229-015-0993-9">[doi]</a><br>
  Kevin T. Kelly, Konstantin Genin, Hanti Lin. <br>
    <i>Synthese</i> 193(4): 1191-1223. <br><br>
Glymour's early work on confirmation theory (1980) eloquently stressed the rhetorical plausibility of Ockham's razor in scientific arguments. His subsequent, seminal research on causal discovery (Spirtes et al. 2000) still concerns methods with a strong bias toward simpler causal models, and it also comes with a story about reliability---the methods are guaranteed to converge to true causal structure in the limit. However, there is a familiar gap between convergent reliability and scientific rhetoric: convergence in the long run is compatible with any conclusion in the short run. For that reason, Carnap (1945) suggested that the proper sense of reliability for scientific inference should lie somewhere between short-run reliability and mere convergence in the limit. One natural such concept is straightest possible convergence to the truth, where straightness is explicated in terms of minimizing reversals of opinion (drawing a conclusion and then replacing it with a logically incompatible one) and cycles of opinion (returning to an opinion previously rejected) prior to convergence. We close the gap between scientific rhetoric and scientific reliability by showing (1) that Ockham's razor is necessary for cycle-optimal convergence to the truth, and (2) that patiently waiting for information to resolve conflicts among simplest hypotheses is necessary for reversal-optimal convergence to the truth. <br><br>

  </li>
			
  <li><b>Theory Choice, Theory Change, and Inductive Truth-Conduciveness.</b> (2015) [<a href="https://www.researchgate.net/publication/301957309_Theory_Choice_Theory_Change_and_Inductive_Truth-Conduciveness">preprint</a>]<br>
    Konstantin Genin, Kevin T. Kelly.<br>
    <a href="http://www.imsc.res.in/tark/TARK2015-proceedings.pdf">Proceedings</a> of the Fifteenth Conference on Theoretical Aspects of Rationality and Knowledge (TARK).<br><br>

    This is an extended abstract for the above paper <i>Learning, Theory Choice, and Belief Revision.</i><br><br>
  </li>
				
  <li><b>Complexity, Ockham's Razor, and Truth.</b> (2014) <a href="http://dx.doi.org/10.1057/9781137403865_9">[doi]</a><br>
    Kevin T. Kelly, Konstantin Genin.<br>
    <i>Modes of Explanation: Affordances for Action and Prediction.</i> Lissack, Michael ed., Palgrave Macmillan. <br><br>

    Ockham's razor says: "Choose the simplest theory compatible with the data." Without Ockham's razor, theoretical science cannot get very far, since there are always ever more complicated explanations compatible with current evidence. Scientific lore pretends that reality is simple---but gravitation works by a quadratic, rather than a linear, law; and what about the shocking failure of parity conservation in particle physics? Ockham speaks so strongly in its favor that demonstrating its falsity resulted in a Nobel Prize in physics (Lee and Yang 1957). So why trust Ockham?<br><br>

  </li>

  <li><b>Student Profiling from Tutoring System Log Data: When do Multiple Graphical Representations Matter?</b> (2013) [<a href="https://www.researchgate.net/publication/301957353_Student_Profiling_from_Tutoring_System_Log_Data_When_do_Multiple_Graphical_Representations_Matter">preprint</a>]  <br>
    Ryan Carlson, Konstantin Genin, Martina Rau, Richard Scheines. <br>
    Proceedings of the Education Data Mining (EDM) Conference.<br><br>

    We analyze log-data generated by an experiment with Fractions Tutor, an intelligent tutoring system. The experiment compares the educational effectiveness of instruction with single and multiple graphical representations. We cluster students by their learning strategy and find that the association between experimental condition and learning outcome is found among students implementing just one of the learning strategies. The behaviors that characterize this group illuminate the mechanism underlying the effectiveness of multiple representations and suggest strategies for tailoring instruction to individual students.

  </li> 			
		
		     	
<h2>Accepted for Presentation</h2> 
<li><b>How Inductive is Bayesian Conditioning? </b> (2017) <a href="papers/conditioning_long.pdf">[abstract]</a> <br> 
Konstantin Genin<br>
    Accepted for presentation at <a href="https://experienceandupdating.wordpress.com/">Experience and Updating Workshop</a>, Bochum. <br><br>
 Bayesian conditioning is widely considered to license inductive inferences to universal hypotheses. However, several authors [Kelly, 1996, Shear et al., 2017] have called attention to a sense in which those inferences are essentially deductive: if H has high credence after conditioning on E, then the material condition E âŠƒ H has even higher prior probability. In this note, I show that a similar feature attends Jeffrey conditioning. Furthermore, I briefly address the extent of non-deductive undermining of prior beliefs. <br><br>
</li>


    <li><b>A Topological Explanation of Empirical Simplicity. </b> (2016) <a href="https://www.researchgate.net/publication/316250000_A_Topological_Explanation_of_Empirical_Simplicity">[preprint]</a><br>
    Kevin T. Kelly, Konstantin Genin<br>
    Presented at the 2016 Philosophy of Science Meeting.<br><br>

    
    We present and motivate a new explication of empirical simplicity that avoids many of the problems with earlier accounts. The proposal is grounded in information topology, the topological space generated by the set of all possible information states inquiry might encounter. Our proposal is closely related to Popper's, but we show that it improves upon his in at least two respects: maximal simplicity is equivalent to refutability and stronger hypotheses are not simpler. Finally, we explain how to extend the topological viewpoint to statistical inductive inference. <br><br>

    </li>
    </ul>
	</div>

<p id=subs> Last update: 04-2017. </p> 
	

</div>


</body>
</html> 
